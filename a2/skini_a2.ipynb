{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGR-E 516 Assignment 2\n",
    "## Srinivas Kini\n",
    "## skini@iu.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spark libraries\n",
    "import math\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 14:37:37 WARN Utils: Your hostname, Srinivass-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.0.0.229 instead (on interface en0)\n",
      "23/04/14 14:37:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 14:37:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session \n",
    "spark = SparkSession.builder.appName('skini-a2').getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read the parking violations file\n",
    "ny_df = spark.read.options(header=True, inferschema=True).csv(\"ny_parking_violations.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns with _ for ease of use in Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summons_number',\n",
       " 'plate_id',\n",
       " 'registration_state',\n",
       " 'plate_type',\n",
       " 'issue_date']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming columns for ease of use in Spark SQL\n",
    "for column in ny_df.columns:\n",
    "    new_col_name = '_'.join(column.lower().split(' '))\n",
    "    ny_df = ny_df.withColumnRenamed(column, new_col_name)\n",
    "ny_df.columns[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temp. VIEW for Spark SQl\n",
    "table_name = \"parking_violations\"\n",
    "ny_df.createOrReplaceTempView(table_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Q1: When are tickets most likely to be issued?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on Date\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "| issued_on|tickets|\n",
      "+----------+-------+\n",
      "|08/04/2022|  66726|\n",
      "|08/05/2022|  65393|\n",
      "|08/02/2022|  64876|\n",
      "|06/30/2022|  64846|\n",
      "|07/19/2022|  64815|\n",
      "+----------+-------+\n",
      "\n",
      "\n",
      "Based on Year\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|year|tickets|\n",
      "+----+-------+\n",
      "|2022|9154317|\n",
      "|2023|2380085|\n",
      "|2021|    477|\n",
      "|2024|    117|\n",
      "|2020|     90|\n",
      "+----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Based on Date\\n\")\n",
    "q1_query = f'''\n",
    "SELECT\n",
    "  SUBSTR(issue_date, 1, 10) AS issued_on,\n",
    "  COUNT(*) AS tickets\n",
    "FROM {table_name}\n",
    "GROUP BY issued_on\n",
    "ORDER BY tickets DESC\n",
    "LIMIT 5\n",
    "'''.strip()\n",
    "\n",
    "spark.sql(q1_query).show()\n",
    "\n",
    "print(\"\\nBased on Year\\n\")\n",
    "q1_query = f'''\n",
    "SELECT\n",
    "  YEAR(TO_DATE(CAST(UNIX_TIMESTAMP(issue_date,'MM/dd/yyyy') AS timestamp))) AS year,\n",
    "  COUNT(*) AS tickets\n",
    "FROM {table_name}\n",
    "GROUP BY year\n",
    "ORDER BY tickets DESC\n",
    "LIMIT 5\n",
    "'''.strip()\n",
    "\n",
    "spark.sql(q1_query).show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Q2: What are the most common years and types of cars to be ticketed?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+\n",
      "|year| make|num_tickets|\n",
      "+----+-----+-----------+\n",
      "|2021|TOYOT|     117999|\n",
      "|2019|HONDA|     113890|\n",
      "|2021|HONDA|     107202|\n",
      "|2020|HONDA|     104349|\n",
      "|2022|TOYOT|      95782|\n",
      "+----+-----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "q2_query = f'''\n",
    "SELECT\n",
    "  vehicle_year AS year,\n",
    "  vehicle_make AS make,\n",
    "  COUNT(*) AS num_tickets\n",
    "FROM {table_name}\n",
    "WHERE vehicle_year IS NOT NULL AND vehicle_year <> 0 AND vehicle_make IS NOT NULL\n",
    "GROUP BY vehicle_year, vehicle_make\n",
    "ORDER BY num_tickets DESC\n",
    "LIMIT 5\n",
    "'''.strip()\n",
    "\n",
    "spark.sql(q2_query).show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Q3: Where are tickets most commonly issued?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By violation_county\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+\n",
      "|violation_county|tickets|\n",
      "+----------------+-------+\n",
      "|              NY|2450153|\n",
      "|              QN|1858441|\n",
      "|              BK|1732079|\n",
      "|              BX|1497854|\n",
      "|               K|1365103|\n",
      "+----------------+-------+\n",
      "\n",
      "By violation_precinct\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|violation_precinct|tickets|\n",
      "+------------------+-------+\n",
      "|                 0|5349526|\n",
      "|                19| 282466|\n",
      "|                13| 254057|\n",
      "|                 6| 224686|\n",
      "|               114| 221523|\n",
      "+------------------+-------+\n",
      "\n",
      "By violation_location\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:========================================================(17 + 0) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|violation_location|tickets|\n",
      "+------------------+-------+\n",
      "|                19| 282466|\n",
      "|                13| 254057|\n",
      "|                 6| 224686|\n",
      "|               114| 221523|\n",
      "|                14| 190012|\n",
      "+------------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "q3_query = '''\n",
    "SELECT\n",
    "  {} AS {}, COUNT(*) AS tickets\n",
    "FROM parking_violations\n",
    "WHERE {} IS NOT NULL\n",
    "GROUP BY {}\n",
    "ORDER BY tickets DESC\n",
    "LIMIT 5\n",
    "'''.strip()\n",
    "\n",
    "print(\"By violation_county\\n\")\n",
    "spark.sql(q3_query.format(*([\"violation_county\"] * 4))).show()\n",
    "\n",
    "print(\"By violation_precinct\\n\")\n",
    "spark.sql(q3_query.format(*([\"violation_precinct\"] * 4))).show()\n",
    "\n",
    "print(\"By violation_location\\n\")\n",
    "spark.sql(q3_query.format(*([\"violation_location\"] * 4))).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Q4: Which color of the vehicle is most likely to get a ticket?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:===================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|color|num_tickets|\n",
      "+-----+-----------+\n",
      "|   GY|    2275457|\n",
      "|   WH|    2055818|\n",
      "|   BK|    1992788|\n",
      "|   BL|     760235|\n",
      "|WHITE|     671757|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "q4_query = f'''\n",
    "SELECT vehicle_color AS color,\n",
    "  COUNT(*) AS num_tickets\n",
    "FROM parking_violations\n",
    "WHERE vehicle_color IS NOT NULL\n",
    "GROUP BY vehicle_color\n",
    "ORDER BY num_tickets DESC\n",
    "LIMIT 5\n",
    "'''.strip()\n",
    "spark.sql(q4_query).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Based on a K-Means algorithm, please try to answer the following question: • Given a Black vehicle parking illegally at 34510, 10030, 34050 (street codes). What is the probability that it will get an ticket? (very rough prediction)._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first step is to filter out the data, for this data let us consider a cluster size of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_km = ny_df.select('vehicle_color', 'street_code1', 'street_code2', 'street_code3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform K-Means (k=4) and then show the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['street_code1', 'street_code2', 'street_code3'], outputCol=\"features\")\n",
    "ny_km = assembler.transform(ny_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2969.14010497, 1072.02717556,  661.48646836]),\n",
       " array([50044.5112846 , 58800.13552356, 58709.93333802]),\n",
       " array([61858.56842042, 19162.26310865, 18767.0727426 ]),\n",
       " array([21476.39742951, 25580.76549152, 25929.22811102])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(featuresCol='features', k=4, seed=10)\n",
    "fit = kmeans.fit(ny_km)\n",
    "transformed = fit.transform(ny_km)\n",
    "cluster_centers = fit.clusterCenters()\n",
    "cluster_centers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filer out the data for the necessary street codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+------------+------------+--------------------+----------+\n",
      "|vehicle_color|street_code1|street_code2|street_code3|            features|prediction|\n",
      "+-------------+------------+------------+------------+--------------------+----------+\n",
      "|        WHITE|       10030|        6880|        6980|[10030.0,6880.0,6...|         0|\n",
      "|           WH|       10030|       40404|       40404|[10030.0,40404.0,...|         3|\n",
      "|         BLUE|       10030|       57490|       28230|[10030.0,57490.0,...|         3|\n",
      "|           WH|       10030|       57490|       28230|[10030.0,57490.0,...|         3|\n",
      "|        WHITE|       10030|       42630|        6080|[10030.0,42630.0,...|         3|\n",
      "+-------------+------------+------------+------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tran_fil = transformed.where(transformed['street_code1'].isin(34510, 10030, 34050))\n",
    "tran_fil.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, clean the data so all codes for the color 'Black' are taken into consideration. Along with this, we will use the original dataframe to get the count of black cars and all cars. This will be used to calculate the probability grouped by the street code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:==========================>                              (8 + 8) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+------------------+\n",
      "|street_code1|n_blk|n_all|              prob|\n",
      "+------------+-----+-----+------------------+\n",
      "|       34050| 1556| 8515| 18.27363476218438|\n",
      "|       34510| 2182|12279|17.770176724488966|\n",
      "|       10030|  228| 1141| 19.98247151621385|\n",
      "+------------+-----+-----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prob = tran_fil.groupBy('street_code1').agg(count(when(ny_df[\"vehicle_color\"].isin('Black', 'BK.', 'BLK.', 'BLAC', 'BK', 'BLK', 'BCK', 'BC', 'BLACK'), True)).\n",
    "                                              alias('n_blk'),count(ny_df[\"vehicle_color\"]).alias('n_all'))\\\n",
    "                                                  .withColumn('prob', col(\"n_blk\")/col(\"n_all\") * 100 )\n",
    "prob.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see here that the probability of a black car getting a ticket at 34050 is 18.27 %, 34510 is 17.77% and 10030 is 19.98% ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GAME_ID: integer (nullable = true)\n",
      " |-- MATCHUP: string (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- W: string (nullable = true)\n",
      " |-- FINAL_MARGIN: integer (nullable = true)\n",
      " |-- SHOT_NUMBER: integer (nullable = true)\n",
      " |-- PERIOD: integer (nullable = true)\n",
      " |-- GAME_CLOCK: timestamp (nullable = true)\n",
      " |-- SHOT_CLOCK: double (nullable = true)\n",
      " |-- DRIBBLES: integer (nullable = true)\n",
      " |-- TOUCH_TIME: double (nullable = true)\n",
      " |-- SHOT_DIST: double (nullable = true)\n",
      " |-- PTS_TYPE: integer (nullable = true)\n",
      " |-- SHOT_RESULT: string (nullable = true)\n",
      " |-- CLOSEST_DEFENDER: string (nullable = true)\n",
      " |-- CLOSEST_DEFENDER_PLAYER_ID: integer (nullable = true)\n",
      " |-- CLOSE_DEF_DIST: double (nullable = true)\n",
      " |-- FGM: integer (nullable = true)\n",
      " |-- PTS: integer (nullable = true)\n",
      " |-- player_name: string (nullable = true)\n",
      " |-- player_id: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nba = spark.read.options(header=True, inferschema=True).csv(\"shot_logs.csv\")\n",
    "nba.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Q1: For each pair of the players (A, B), we define the fear sore of A when facing B is the hit_\n",
    "## _rate, such that B is closet defender when A is shooting. Based on the fear sore, for each_\n",
    "## _player, please find out who is his ”most unwanted defender”_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we will group the data by the player and the closest defender and aggregate the shots that they have missed and hit for that defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+----+------+\n",
      "|     player_name|  closest_defender|hits|misses|\n",
      "+----------------+------------------+----+------+\n",
      "|   brian roberts|        Gasol, Pau|   0|     1|\n",
      "|    al jefferson| Hardaway Jr., Tim|   0|     1|\n",
      "|     cody zeller|     Price, Ronnie|   0|     1|\n",
      "|       gary neal|     Beal, Bradley|   3|     3|\n",
      "|       gary neal|     Smart, Marcus|   0|     4|\n",
      "|gerald henderson|    Bazemore, Kent|   0|     2|\n",
      "|    kemba walker|     Williams, Lou|   1|     2|\n",
      "|lance stephenson|    Fournier, Evan|   0|     2|\n",
      "| marvin williams| Early, Cleanthony|   1|     1|\n",
      "|  gordon hayward|Aldridge, LaMarcus|   2|     5|\n",
      "|  gordon hayward|    Bazemore, Kent|   1|     1|\n",
      "|   trevor booker|   Thompson, Jason|   3|     3|\n",
      "|   trevor booker|    Frye, Channing|   1|     2|\n",
      "|     enes kanter|   Chandler, Tyson|   1|     6|\n",
      "|      dante exum|      Williams, Mo|   0|     3|\n",
      "|      jon ingles|     Jack, Jarrett|   1|     1|\n",
      "|      jon ingles|     Williams, Lou|   1|     5|\n",
      "|     rudy gobert|       Foye, Randy|   1|     1|\n",
      "|     rudy gobert|      Wade, Dwyane|   1|     1|\n",
      "|   carlos boozer|     Jefferson, Al|   2|     2|\n",
      "+----------------+------------------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate hits and misses based on SHOT_RESULT\n",
    "hit_rates = nba.groupBy(\"player_name\",\"closest_defender\")\\\n",
    "    .agg(count(when(nba[\"SHOT_RESULT\"]==\"made\", True))\\\n",
    "    .alias('hits'),count(\"SHOT_RESULT\").alias('misses'))\n",
    "hit_rates.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To calculate the hit rate, we can use the following equation\n",
    "### hit_rate = hits / (hits + misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+----+------+--------+\n",
      "| player_name| closest_defender|hits|misses|hit_rate|\n",
      "+------------+-----------------+----+------+--------+\n",
      "|aaron brooks|   Thompson, Klay|   1|     3|    0.25|\n",
      "|aaron brooks|Livingston, Shaun|   1|     2|    0.33|\n",
      "|aaron brooks|     Smith, Jason|   1|     2|    0.33|\n",
      "|aaron brooks|    Lee, Courtney|   1|     3|    0.25|\n",
      "|aaron brooks| Carroll, DeMarre|   1|     1|     0.5|\n",
      "|aaron brooks|    Nurkic, Jusuf|   0|     2|     0.0|\n",
      "|aaron brooks|     Lopez, Robin|   2|     3|     0.4|\n",
      "|aaron brooks|    Harris, Devin|   0|     1|     0.0|\n",
      "|aaron brooks|      Green, Jeff|   0|     1|     0.0|\n",
      "|aaron brooks|     LaVine, Zach|   1|     3|    0.25|\n",
      "|aaron brooks|    Ariza, Trevor|   1|     1|     0.5|\n",
      "|aaron brooks|   Hayes, Charles|   0|     2|     0.0|\n",
      "|aaron brooks| Williams, Marvin|   1|     2|    0.33|\n",
      "|aaron brooks|  Napier, Shabazz|   4|     6|     0.4|\n",
      "|aaron brooks|  Lillard, Damian|   3|     6|    0.33|\n",
      "|aaron brooks|      Scola, Luis|   0|     1|     0.0|\n",
      "|aaron brooks|      Gasol, Marc|   1|     1|     0.5|\n",
      "|aaron brooks|      Exum, Dante|   0|     3|     0.0|\n",
      "|aaron brooks|       Lawson, Ty|   0|     5|     0.0|\n",
      "|aaron brooks|    Green, Willie|   1|     2|    0.33|\n",
      "+------------+-----------------+----+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hit_rates = hit_rates.withColumn('hit_rate', round(hit_rates['hits']/(hit_rates['hits'] + hit_rates['misses']), 2))\n",
    "hit_rates.orderBy(hit_rates['player_name']).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove duplicate values for the hit_rate we will rank the data based on player_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+----+------+--------+----+\n",
      "| player_name|    closest_defender|hits|misses|hit_rate|rank|\n",
      "+------------+--------------------+----+------+--------+----+\n",
      "|aaron brooks|       Nurkic, Jusuf|   0|     2|     0.0|   1|\n",
      "|aaron brooks|       Harris, Devin|   0|     1|     0.0|   2|\n",
      "|aaron brooks|         Green, Jeff|   0|     1|     0.0|   3|\n",
      "|aaron brooks|      Hayes, Charles|   0|     2|     0.0|   4|\n",
      "|aaron brooks|         Scola, Luis|   0|     1|     0.0|   5|\n",
      "|aaron brooks|         Exum, Dante|   0|     3|     0.0|   6|\n",
      "|aaron brooks|          Lawson, Ty|   0|     5|     0.0|   7|\n",
      "|aaron brooks|     Crawford, Jamal|   0|     1|     0.0|   8|\n",
      "|aaron brooks|      Fournier, Evan|   0|     1|     0.0|   9|\n",
      "|aaron brooks|       O'Quinn, Kyle|   0|     1|     0.0|  10|\n",
      "|aaron brooks|        Wear, Travis|   0|     1|     0.0|  11|\n",
      "|aaron brooks|   Dos Santos, Atila|   0|     1|     0.0|  12|\n",
      "|aaron brooks|        Hairston, PJ|   0|     1|     0.0|  13|\n",
      "|aaron brooks|     Johnson, Wesley|   0|     1|     0.0|  14|\n",
      "|aaron brooks|      Powell, Dwight|   0|     1|     0.0|  15|\n",
      "|aaron brooks|      Rivers, Austin|   0|     2|     0.0|  16|\n",
      "|aaron brooks|Antetokounmpo, Gi...|   0|     1|     0.0|  17|\n",
      "|aaron brooks|     Splitter, Tiago|   0|     1|     0.0|  18|\n",
      "|aaron brooks|      Johnson, Chris|   0|     2|     0.0|  19|\n",
      "|aaron brooks|    Schroder, Dennis|   0|     1|     0.0|  20|\n",
      "+------------+--------------------+----+------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mud = hit_rates.withColumn(\"rank\",row_number().over(Window.partitionBy(\"player_name\")\\\n",
    "    .orderBy(hit_rates[\"hit_rate\"].asc())))\n",
    "mud.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we will only get those ranks which are 1 to get the 'Most Unwanted Defender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------+----+\n",
      "|     player_name|most_unwanted_defender|rank|\n",
      "+----------------+----------------------+----+\n",
      "|    aaron brooks|         Nurkic, Jusuf|   1|\n",
      "|    aaron gordon|        Rivers, Austin|   1|\n",
      "| al farouq aminu|        Johnson, James|   1|\n",
      "|      al horford|           Diaw, Boris|   1|\n",
      "|    al jefferson|     Hardaway Jr., Tim|   1|\n",
      "|   alan anderson|            Leuer, Jon|   1|\n",
      "|     alan crabbe|      Sefolosha, Thabo|   1|\n",
      "|        alex len|       Knight, Brandon|   1|\n",
      "|   alexis ajinca|          Meeks, Jodie|   1|\n",
      "|      alonzo gee|          Korver, Kyle|   1|\n",
      "|amare stoudemire|            Deng, Luol|   1|\n",
      "|    amir johnson|         Grant, Jerami|   1|\n",
      "|  andre drummond|         James, LeBron|   1|\n",
      "|  andre iguodala|           Lowry, Kyle|   1|\n",
      "|    andre miller|          Turner, Evan|   1|\n",
      "|  andre roberson|        Ginobili, Manu|   1|\n",
      "|    andrew bogut|          Ibaka, Serge|   1|\n",
      "|  andrew wiggins|        Sanders, Larry|   1|\n",
      "| anthony bennett|        Ajinca, Alexis|   1|\n",
      "|   anthony davis|     Mbah a Moute, Luc|   1|\n",
      "+----------------+----------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mud = mud.where(mud['rank'] == 1).withColumnRenamed(\"closest_defender\", \"most_unwanted_defender\")\\\n",
    "    .select(\"player_name\", \"most_unwanted_defender\", \"rank\")\n",
    "mud.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Q2: For each player, we define the comfortable zone of shooting is a matrix of,_\n",
    "## _{SHOT DIST, CLOSE DEF DIST, SHOT CLOCK}_\n",
    "## _Please develop a Spark-based algorithm to classify each player’s records into 4 comfort-_\n",
    "## _able zones. Considering the hit rate, which zone is the best for James Harden, Chris Paul, Stephen Curry, and Lebron James._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To calculate comfortable zones for these players, we can make use of K-Means clustering where each cluster maps to a zone. Since we need 4 zones, there will be 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------+--------------+----------+\n",
      "|         player_name|shot_result|shot_dist|close_def_dist|shot_clock|\n",
      "+--------------------+-----------+---------+--------------+----------+\n",
      "|       brian roberts|     missed|     19.6|           4.6|      16.7|\n",
      "|       brian roberts|     missed|     23.8|           5.5|      17.6|\n",
      "|       brian roberts|       made|     20.5|           5.3|      14.4|\n",
      "|       brian roberts|     missed|     24.5|           5.2|      15.3|\n",
      "|        al jefferson|       made|     19.3|           7.6|      10.0|\n",
      "|        al jefferson|       made|      7.7|           2.2|       3.8|\n",
      "|         cody zeller|     missed|     18.1|           4.9|      12.1|\n",
      "|         cody zeller|     missed|      3.1|           2.4|      24.0|\n",
      "|           gary neal|       made|     17.4|           3.1|      11.0|\n",
      "|           gary neal|     missed|     25.5|           5.5|      11.8|\n",
      "|           gary neal|     missed|      6.5|           0.2|      14.8|\n",
      "|    gerald henderson|       made|      5.3|           0.8|      20.8|\n",
      "|    gerald henderson|     missed|     22.5|           6.9|      12.7|\n",
      "|    gerald henderson|       made|      4.9|           1.7|      15.0|\n",
      "|    gerald henderson|     missed|     20.6|           5.1|      13.3|\n",
      "|        kemba walker|     missed|     15.3|           3.4|      18.0|\n",
      "|        kemba walker|     missed|     24.1|           2.8|       1.0|\n",
      "|        kemba walker|       made|     16.2|           3.9|      13.1|\n",
      "|michael kidd-gilc...|       made|      4.0|           2.9|      13.6|\n",
      "|    lance stephenson|       made|      3.2|           3.9|      17.9|\n",
      "+--------------------+-----------+---------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zones = nba.select('player_name','shot_result','shot_dist','close_def_dist','shot_clock').dropna().dropDuplicates()\n",
    "zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=['shot_dist','close_def_dist','shot_clock'], outputCol=\"features\", handleInvalid=\"skip\")\n",
    "kmeans = KMeans(featuresCol='features', k=4, seed=10)    \n",
    "t_data = assembler.transform(zones)\n",
    "op_fit = kmeans.fit(t_data)\n",
    "zones = op_fit.transform(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------+--------------+----------+---------------+----------+\n",
      "|         player_name|shot_result|shot_dist|close_def_dist|shot_clock|       features|prediction|\n",
      "+--------------------+-----------+---------+--------------+----------+---------------+----------+\n",
      "|       brian roberts|     missed|     19.6|           4.6|      16.7|[19.6,4.6,16.7]|         1|\n",
      "|       brian roberts|     missed|     23.8|           5.5|      17.6|[23.8,5.5,17.6]|         1|\n",
      "|       brian roberts|       made|     20.5|           5.3|      14.4|[20.5,5.3,14.4]|         1|\n",
      "|       brian roberts|     missed|     24.5|           5.2|      15.3|[24.5,5.2,15.3]|         1|\n",
      "|        al jefferson|       made|     19.3|           7.6|      10.0|[19.3,7.6,10.0]|         2|\n",
      "|        al jefferson|       made|      7.7|           2.2|       3.8|  [7.7,2.2,3.8]|         0|\n",
      "|         cody zeller|     missed|     18.1|           4.9|      12.1|[18.1,4.9,12.1]|         1|\n",
      "|         cody zeller|     missed|      3.1|           2.4|      24.0| [3.1,2.4,24.0]|         3|\n",
      "|           gary neal|       made|     17.4|           3.1|      11.0|[17.4,3.1,11.0]|         2|\n",
      "|           gary neal|     missed|     25.5|           5.5|      11.8|[25.5,5.5,11.8]|         1|\n",
      "|           gary neal|     missed|      6.5|           0.2|      14.8| [6.5,0.2,14.8]|         3|\n",
      "|    gerald henderson|       made|      5.3|           0.8|      20.8| [5.3,0.8,20.8]|         3|\n",
      "|    gerald henderson|     missed|     22.5|           6.9|      12.7|[22.5,6.9,12.7]|         1|\n",
      "|    gerald henderson|       made|      4.9|           1.7|      15.0| [4.9,1.7,15.0]|         3|\n",
      "|    gerald henderson|     missed|     20.6|           5.1|      13.3|[20.6,5.1,13.3]|         1|\n",
      "|        kemba walker|     missed|     15.3|           3.4|      18.0|[15.3,3.4,18.0]|         1|\n",
      "|        kemba walker|     missed|     24.1|           2.8|       1.0| [24.1,2.8,1.0]|         2|\n",
      "|        kemba walker|       made|     16.2|           3.9|      13.1|[16.2,3.9,13.1]|         1|\n",
      "|michael kidd-gilc...|       made|      4.0|           2.9|      13.6| [4.0,2.9,13.6]|         0|\n",
      "|    lance stephenson|       made|      3.2|           3.9|      17.9| [3.2,3.9,17.9]|         3|\n",
      "+--------------------+-----------+---------+--------------+----------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zones.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we can calculate the hit_rate like we did for the previous question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = zones.groupBy(\"prediction\")\\\n",
    "    .agg(count(when(zones[\"SHOT_RESULT\"]==\"made\", True))\\\n",
    "    .alias('hits'),count(\"SHOT_RESULT\").alias('misses'))\n",
    "zones = zones.withColumn('hit_rate', round(zones['hits']/(zones['hits'] + zones['misses']), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the previous dataframe, let us fetch the hit rates for James Harden, Chris Paul, Stephen Curry, and Lebron James for all defenders and then calculate the Average hit_rate for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------------+\n",
      "|  player_name|round(avg(hit_rate), 2)|\n",
      "+-------------+-----------------------+\n",
      "| lebron james|                   0.31|\n",
      "|   chris paul|                   0.28|\n",
      "| james harden|                   0.28|\n",
      "|stephen curry|                   0.29|\n",
      "+-------------+-----------------------+\n",
      "\n",
      "+----------+-----+------+--------+\n",
      "|prediction| hits|misses|hit_rate|\n",
      "+----------+-----+------+--------+\n",
      "|         1|12692| 32309|    0.28|\n",
      "|         3|15779| 26674|    0.37|\n",
      "|         2|10589| 28652|    0.27|\n",
      "|         0|16801| 34821|    0.33|\n",
      "+----------+-----+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goats = hit_rates.groupBy(hit_rates['player_name'])\\\n",
    "    .agg(round(avg(hit_rates['hit_rate']), 2))\\\n",
    "    .where(hit_rates['player_name']\\\n",
    "    .isin('james harden', 'stephen curry', 'lebron james', 'chris paul'))\n",
    "    \n",
    "goats.show()\n",
    "zones.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the 2 data frames above we can see that LeBron James belongs to cluster (zone) 0 where was Chris Paul, James Harden and Stephen Curry belong to cluster (zone) 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
